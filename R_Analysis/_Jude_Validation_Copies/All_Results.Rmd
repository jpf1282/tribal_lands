---
title: "All Results"
author: "Jude Bayham"
date: "December 19, 2019"
output: html_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)

```

# Setup
Install these packages if neccessary.
```{r project_setup, message = FALSE, warning = FALSE, include=FALSE}

library(readr)
library(gamlss)
library(tidyr)
library(knitr)
library(DT)
library(dplyr)
library(purrr)
library(stringr)
library(scales)
library(broom)
library(ggplot2)
library(ggbeeswarm)
library(MASS)
library(pscl)
library(boot)
library(nlme)
library(cplm)
library(conflicted)
library(fixest)
library(sjPlot)
library(stargazer)
library(clubSandwich)

conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

load("../processed_data.RData")

#Function to coerce fixest object into stargazer table
fixest_to_coeftest <- function(fixest.object){
  require(fixest)
  #Check if arg1 is fixest class
  if(!class(fixest.object)=="fixest"){
    stop("Not a fixest object")
  }
  
  #Extract the coefficient table
  df <- fixest.object$coeftable 
  
  if(length(fixest.object$obsRemoved)>0){
    cluster.var <- data_t1and2_long$tribe[-fixest.object$obsRemoved]
  } else {
    cluster.var <- data_t1and2_long$tribe
  }
  
  
  df.mod <- df %>%
    mutate(se = as.numeric(sqrt(diag(vcov(fixest.object,cluster=cluster.var)))),
           stat = Estimate/se,
           p = 2*pt(-abs(stat),df=nobs(fixest.object)-fixest.object$nparams)) %>%
    dplyr::select(Estimate,se,stat,p)
  
  
  #Coerce dataframe into matrix
  coeftest.object <- as.matrix(df.mod)
  
  #Capture variable names from df and rename columns to conform to coeftest
  new_names <- list(rownames(df),
                    c("Estimate","Std. Error","t value","Pr(>|t|)"))
  
  #Assign names
  dimnames(coeftest.object) <- new_names
  
  #re-class to coeftest
  class(coeftest.object) <- 'coeftest'
  
  return(coeftest.object)
  
}

#Function to coerce lme object into stargazer table
lme_to_coeftest <- function(lme.object){
  require(clubSandwich)
  #Check if arg1 is fixest class
  if(!class(lme.object)=="lme"){
    stop("Not an lme object")
  }
  
  #Extract the coefficient table
  df <- coef_test(lme.object,
                  vcov = vcovCR(lme.object,
                                type="CR2"))
  
  #Coerce dataframe into matrix
  coeftest.object <- as.matrix(df[,c(1,2,3,5)])
  
  #Capture variable names from df and rename columns to conform to coeftest
  new_names <- list(rownames(df),
                    c("Estimate","Std. Error","t value","Pr(>|t|)"))
  
  #Assign names
  dimnames(coeftest.object) <- new_names
  
  #re-class to coeftest
  class(coeftest.object) <- 'coeftest'
  
  return(coeftest.object)
  
}

###############################################
#Function that runs all specifications, clusters se and returns coeftest objects for printing with stargazer
model.run.t1andt2 <- function(dep.var){

  isnt_out_z <- function(x, thres = 3, na.rm = TRUE) {
    abs(x - mean(x, na.rm = na.rm)) <= thres * sd(x, na.rm = na.rm)
  }
  
  #Considered a version where outliers are dropped - the fixest_to_coeftest function is too fragile (it currently calls data_t1andt2_long from outside of the function)
  model_data <- data_t1and2_long #%>%
    #filter(isnt_out_z((!!as.symbol(dep.var))))
  
  # Fixest models
  model.shell <- list()
  model.shell$lm <- feols(formula(str_c(dep.var," ~ time")),
                    data = model_data)
  model.shell$lmw <- feols(formula(str_c(dep.var," ~ time")),
                     data = model_data, weights = ~wgt)
  model.shell$fem <- feols(formula(str_c(dep.var," ~ time|tribe")),
                    data = model_data)
  model.shell$femw <- feols(formula(str_c(dep.var," ~ time|tribe")),
                     data = model_data, weights = ~wgt)
  
  # Linear Mixed Model
  model.shell$lmm <- lme(formula(str_c(dep.var," ~ time")),
                         data = model_data %>% drop_na(one_of(dep.var),time,tribe),
                         random = ~1|tribe)

  model.shell$lmmw <- lme(formula(str_c(dep.var," ~ time")),
                          data = model_data %>% drop_na(one_of(dep.var),time,tribe),
                          random = ~1|tribe,
                          weights = ~wgt)
  
  model.shell <- modify_at(model.shell,c("lm","lmw","fem","femw"),fixest_to_coeftest)
  model.shell <- modify_at(model.shell,c("lmm","lmmw"),lme_to_coeftest)
  
  return(model.shell)
}

#Robust standard errors following https://rpubs.com/cuborican/xtpoisson
#The function takes a gamlss object (output by gamlss) and a vector of conforming clustering variable
gamlss_clustered_vcov <- function(gamlss.object,cluster=NA){
  require(gamlss)
  # if(is.na(cluster)){
  #   #set cluster to be index
  #   #fc <- index(gamlss.object$mu.x)
  # } else {
  #   #check length conforms
  #   if(!length(cluster)==length(gamlss.object$y)){
  #     stop("Clustering vector provided does not conform; check if there are NAs dropped in estimation.")
  #   }
  # }
  esample <- as.numeric(rownames(as.matrix(gamlss.object$mu.qr$qr)))
  fc <- cluster  #isolates the groups used in estimation
  
  # Calculates the new Meat portion of our covariance matrix
  m <- length(unique(fc))
  k <- length(gamlss.object$mu.coefficients)
  u <- gamlss.object$mu.qr$qr
  u.clust <- matrix(NA, nrow=m, ncol=k)
  for(j in 1:k){
    u.clust[,j] <- tapply(u[,j], as.numeric(fc), sum)
  }
  u.clust <- u.clust[!rowSums(u.clust,dims = 1)==0,] #dropping all clusters with all zeros
  cl.vcov <- vcov(gamlss.object)[1:k,1:k]%*%( t(u.clust) %*% (u.clust))%*%vcov(gamlss.object)[1:k,1:k]
  return(cl.vcov)
}


```


Setting up two datasets: 1) the full data including tribes that may not be present in both time periods, and 2) subset of observations where tribes were present in both periods.
```{r, message = FALSE, warning = FALSE, include=FALSE}
#Constructing datasets
data_long <- distinct(merged_data_record_all_long, tribe, time, FIPS, .keep_all = TRUE) %>%
  ungroup() %>%
  mutate(tribe = factor(tribe),
         time = factor(time)) 

data_t1and2_long <- filter(data_long, tribe %in% tribes_time1and2_lst$tribe)

#Constructing weights
data_long <- data_long %>%
  group_by(tribe,time) %>%
  summarise(wgt=1/n()) %>%
  ungroup() %>%
  left_join(data_long,
            .,
            by=c("tribe","time"))

data_t1and2_long <- data_t1and2_long %>%
  group_by(tribe,time) %>%
  summarise(wgt=1/n()) %>%
  ungroup() %>%
  left_join(data_t1and2_long,
            .,
            by=c("tribe","time"))
  
```


# CCEs Inhabited

```{r CCE, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "n_unique_FIPS"
stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```



# Climate Variables

We analyze the difference between climate variables in the pre-migration lands to the post-migration lands.  We focus on heat index, drought, annual precipitation, and wildfire hazard potential.

## Heat

We begin with the heat index, which counts the number of days per year expected to exceed 100 F.  The following figures display the distribution of days exceeding 100 F in the pre-migration (time 1) and the post-migration (time 2).   
```{r, message = FALSE, warning = FALSE, echo = FALSE}


ggplot(data_long, aes(time, h_100_hist, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()


ggplot(data_t1and2_long, aes(time, h_100_hist, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()

```

We employ a battery of statistical methods to assess the difference between the number of heat days across the historical (time 1) and the present (time 2) CCEs.  The first column of Table S1 presents the results of an OLS regression of heat day CCEs on a dummy indicating present-day areas.  

The present-day and historical ranges of tribes vary within the dataset.  Tribes with larger ranges therefore have more weight in a statistical analysis of the data.  We test the robustness of our analysis to tribe population and range by creating weights inversely proportional to the number of CCEs within a tribes range.  For example, if the historical area of a tribe covered 100 CCEs, then each CCE would have a weight of 1/100 in the regression.  The weighted regression in column 2 provides an estimate of the mean difference across tribes controlling for the weight of tribes that covered more CCEs.

Lastly, there may be unobserved factors specific to the tribe that influence the results.  We control for tribe-specific factors using two related approaches: 1) a linear fixed-effects model and 2) a linear random-effects model.  For each model, we estimate a weighted and unweighted regression.  Standard errors in all specifications are clustered at the tribe level and are robust to heteroskedasticity and serial correlation within a tribe.  

```{r h_100_hist, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}
dep.var <- "h_100_hist"
stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```

The results indicate that the present-day locations experience 2.54 (CI: 1.98-3.10) more 100 F days than the historic locations.  We find the lowest estimate in the weighted random-effects model, 2.07 (CI: 0.31-3.83)) and the highest in the unweighted fixed-effects model, 3.31 (CI: 1.86-3.35).  These results suggest a robust increase in the number of 100 F days in present-day CCEs relative to historical CCEs.

*Is this in line with climate change?*

(2.60+5.50)/5.50=1.47%

## Drought

We use the Palmer Drought Severity Index (PDSI) to assess exposure to drought.  

```{r, message = FALSE, warning = FALSE, echo = FALSE}


ggplot(data_long, aes(time, drt_median, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()


ggplot(data_t1and2_long, aes(time, drt_median, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()

```


```{r drt_median, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "drt_median"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```

The results indicate robust evidence that present-day lands experience more drought than historical boundaries.  The mean PDSI on the historical lands ranges from 

*Side note: why each model?  OLS is simple ANOVA comparison.  FE and RE models control for any variation constant across tribe regions.  In many regression contexts, this method controls for otherwise unobservable factors that remain constant over time.  In this case, there are no other controls so the model is detrending the effect estimate for trends common in the time 1 and time 2 periods.  *

(.28+.062)/.28


## Precipitation


```{r, message = FALSE, warning = FALSE, echo = FALSE}


ggplot(data_long, aes(time, precip, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()


ggplot(data_t1and2_long, aes(time, precip, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()

```


```{r precip, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "precip"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```




## Wildfire Hazard Potential

We use CCE median rather than mean to reduce the influence of outliers.

```{r, message = FALSE, warning = FALSE, echo = FALSE}


ggplot(data_long, aes(time, fire_mean, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()


ggplot(data_t1and2_long, aes(time, fire_mean, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  scale_colour_manual(values = c('#32CD32','#ff0000'),aesthetics = c("colour", "fill")) +
  theme_minimal() +
  xlab("") +
  ylab("") +
  scale_x_discrete(labels = c("time 1" = "Historical",
                              "time 2" = "Present-day")) +
  theme(legend.position = "none") 
  

```
Figure caption: Wildfire hazard potential in historical and present-day CCEs.  While indigenous people were concentrated on fewer total CCEs (width of distribution), the mean WHP is higher in the present-day CCEs than the historical.

```{r fire_median, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "fire_mean"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```


(0.55 + 1.17)/1.17

Mixed evidence

# Oil and Gas


## Oil

Oil production

The distributions are highly skewed.

```{r oil_avg, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "oil_avg"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```

## Gas

Gas production



```{r gas_avg, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "gas_avg"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```

(4,294,304 + 6,083,833)/6,083,833

## Oil and Gas Basins

*I should add logit here to show robust to specification*



```{r og_basin, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "og_basin"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```

## Oil and Gas Wells



```{r og_well_count, message = FALSE, warning = FALSE, echo = FALSE, results='asis'}

dep.var <- "og_well_count"
stargazer::stargazer(model.run.t1andt2(dep.var),type="html",ci=T)
```




# Federal Lands


```{r, message = FALSE, warning = FALSE, echo = FALSE}


ggplot(data_long, aes(time, p_all, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()


ggplot(data_t1and2_long, aes(time, p_all, colour = time)) +
  geom_boxplot() +
  geom_quasirandom(alpha = 1/10, varwidth = TRUE) +
  theme_minimal()

```


```{r p_all, message = FALSE, warning = FALSE, echo = FALSE}

bezi_data <- mutate(data_t1and2_long, 
                    p_all = ifelse(p_all >= 1, .99999, p_all)) %>%
  filter(!is.na(p_all)) %>%
  dplyr::select(time, tribe, p_all,wgt)

bezi_model <- gamlss(p_all ~ time, family = BEZI, data = bezi_data, trace = F)

bezi_model_w <-  gamlss(p_all ~ time, family = BEZI, data = bezi_data, trace = F,weights = wgt)

tab_model(bezi_model,bezi_model_w)

sqrt(diag(gamlss_clustered_vcov(bezi_model,cluster = bezi_data$tribe)))
sqrt(diag(gamlss_clustered_vcov(bezi_model_w,cluster = bezi_data$tribe)))
#Cluster robust standard errors
  # map(list(bezi_model,bezi_model_w),
  #     function(x){
  #   
  # }) %>%
  # data.table::rbindlist()


```
